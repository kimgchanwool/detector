{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 868538,
     "status": "ok",
     "timestamp": 1632894580665,
     "user": {
      "displayName": "장경희",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05148120440289478711"
     },
     "user_tz": -540
    },
    "id": "8BY3DxMXY7AP",
    "outputId": "75fd40ee-b927-41b0-ad36-94251aa3cd28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mmcv-full\n",
      "  Downloading mmcv-full-1.3.14.tar.gz (324 kB)\n",
      "\u001b[K     |████████████████████████████████| 324 kB 8.3 MB/s \n",
      "\u001b[?25hCollecting addict\n",
      "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (1.19.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (21.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (7.1.2)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (3.13)\n",
      "Collecting yapf\n",
      "  Downloading yapf-0.31.0-py2.py3-none-any.whl (185 kB)\n",
      "\u001b[K     |████████████████████████████████| 185 kB 67.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mmcv-full) (2.4.7)\n",
      "Building wheels for collected packages: mmcv-full\n",
      "  Building wheel for mmcv-full (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for mmcv-full: filename=mmcv_full-1.3.14-cp37-cp37m-linux_x86_64.whl size=31614925 sha256=204beb9bca2c4a58886e1738b1bd8e24ebcb4ee4042608d6a2d6a1789ecdf2e2\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/54/62/69c99dc3c9937bca64126f81cbe315ae6c8e6e98c43fa7392d\n",
      "Successfully built mmcv-full\n",
      "Installing collected packages: yapf, addict, mmcv-full\n",
      "Successfully installed addict-2.4.0 mmcv-full-1.3.14 yapf-0.31.0\n"
     ]
    }
   ],
   "source": [
    "!pip install mmcv-full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2152,
     "status": "ok",
     "timestamp": 1632894582784,
     "user": {
      "displayName": "장경희",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05148120440289478711"
     },
     "user_tz": -540
    },
    "id": "0H7MCCFCajM4",
    "outputId": "1905694e-e76c-4871-dae3-a8caab1004ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mmdetection'...\n",
      "remote: Enumerating objects: 21083, done.\u001b[K\n",
      "remote: Total 21083 (delta 0), reused 0 (delta 0), pack-reused 21083\u001b[K\n",
      "Receiving objects: 100% (21083/21083), 24.81 MiB | 30.57 MiB/s, done.\n",
      "Resolving deltas: 100% (14743/14743), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/open-mmlab/mmdetection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1632895200712,
     "user": {
      "displayName": "장경희",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05148120440289478711"
     },
     "user_tz": -540
    },
    "id": "BvxucyZZes_C",
    "outputId": "2db14e16-2ca2-441f-e65c-816a6ef35e56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/mmdetection\n"
     ]
    }
   ],
   "source": [
    "%cd mmdetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGhoklrqhAi8"
   },
   "outputs": [],
   "source": [
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 332,
     "status": "ok",
     "timestamp": 1632895222018,
     "user": {
      "displayName": "장경희",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05148120440289478711"
     },
     "user_tz": -540
    },
    "id": "pVrjIQmBhfpL"
   },
   "outputs": [],
   "source": [
    "!mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15127,
     "status": "ok",
     "timestamp": 1632897132686,
     "user": {
      "displayName": "장경희",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05148120440289478711"
     },
     "user_tz": -540
    },
    "id": "nzthLAXCiH17",
    "outputId": "787b32fd-b6a6-4889-e13f-2dbfb7ed551b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-09-29 06:33:18--  https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.88.36.78\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.88.36.78|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 167287506 (160M) [application/octet-stream]\n",
      "Saving to: ‘/content/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth’\n",
      "\n",
      "/content/mmdetectio 100%[===================>] 159.54M  13.0MB/s    in 14s     \n",
      "\n",
      "2021-09-29 06:33:33 (11.5 MB/s) - ‘/content/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth’ saved [167287506/167287506]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O /content/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 7828,
     "status": "ok",
     "timestamp": 1632899094214,
     "user": {
      "displayName": "장경희",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05148120440289478711"
     },
     "user_tz": -540
    },
    "id": "dBlthlYkksUk"
   },
   "outputs": [],
   "source": [
    "from mmdet.apis import init_detector, inference_detector, show_result_pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3020,
     "status": "ok",
     "timestamp": 1632895357526,
     "user": {
      "displayName": "장경희",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05148120440289478711"
     },
     "user_tz": -540
    },
    "id": "zwvbTsQ-5hnb",
    "outputId": "3f48190d-41b6-4d2f-8aef-4cdf807994cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-09-29 06:03:55--  https://download.openmmlab.com/mmdetection/data/kitti_tiny.zip\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.88.36.78\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.88.36.78|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6918271 (6.6M) [application/zip]\n",
      "Saving to: ‘kitti_tiny.zip’\n",
      "\n",
      "kitti_tiny.zip      100%[===================>]   6.60M  4.15MB/s    in 1.6s    \n",
      "\n",
      "2021-09-29 06:03:58 (4.15 MB/s) - ‘kitti_tiny.zip’ saved [6918271/6918271]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download, decompress the data\n",
    "!wget https://download.openmmlab.com/mmdetection/data/kitti_tiny.zip\n",
    "!unzip kitti_tiny.zip > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0q11t4VEpr9"
   },
   "outputs": [],
   "source": [
    "#CLASSES = ('Car', 'Van', 'Truck', 'Pedestrian', 'Person_sitting', 'Cyclist', 'Tram', 'Misc', 'DontCare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1632899102043,
     "user": {
      "displayName": "장경희",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05148120440289478711"
     },
     "user_tz": -540
    },
    "id": "4Zq9WX_IOKHk"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os.path as osp\n",
    "\n",
    "import mmcv\n",
    "import numpy as np\n",
    "\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.custom import CustomDataset\n",
    "\n",
    "@DATASETS.register_module(force=True)\n",
    "class KittiTinyDataset(CustomDataset):\n",
    "\n",
    "    CLASSES = ('Car', 'Pedestrian', 'Cyclist')\n",
    "    \n",
    "    ### self.ann_file : /content/kitti_tiny/train.txt\n",
    "    ### self.img_prefix : /content/kitti_tiny/training/image_2\n",
    "    ### ann_file : /content/kitti_tiny/train.txt\n",
    "\n",
    "    def load_annotations(self, ann_file):\n",
    "        print(\"self.ann_file : \", self.ann_file)\n",
    "        print(\"self.img_prefix: \", self.img_prefix)\n",
    "\n",
    "        cat2label = {k: i for i, k in enumerate(self.CLASSES)}\n",
    "        # load image list from file\n",
    "        image_list = mmcv.list_from_file(self.ann_file)\n",
    "    \n",
    "        data_infos = []\n",
    "        # convert annotations to middle format\n",
    "        for image_id in image_list:\n",
    "            filename = f'{self.img_prefix}/{image_id}.jpeg'\n",
    "            image = mmcv.imread(filename)\n",
    "            height, width = image.shape[:2]\n",
    "    \n",
    "            data_info = dict(filename=f'{image_id}.jpeg', width=width, height=height)\n",
    "    \n",
    "            # load annotations\n",
    "            label_prefix = self.img_prefix.replace('image_2', 'label_2')\n",
    "            lines = mmcv.list_from_file(osp.join(label_prefix, f'{image_id}.txt'))\n",
    "    \n",
    "            content = [line.strip().split(' ') for line in lines]\n",
    "            bbox_names = [x[0] for x in content]\n",
    "            bboxes = [[float(info) for info in x[4:8]] for x in content]\n",
    "    \n",
    "            gt_bboxes = []\n",
    "            gt_labels = []\n",
    "            gt_bboxes_ignore = []\n",
    "            gt_labels_ignore = []\n",
    "    \n",
    "            # filter 'DontCare'\n",
    "            for bbox_name, bbox in zip(bbox_names, bboxes):\n",
    "                if bbox_name in cat2label:\n",
    "                    gt_labels.append(cat2label[bbox_name])\n",
    "                    gt_bboxes.append(bbox)\n",
    "                else:\n",
    "                    gt_labels_ignore.append(-1)\n",
    "                    gt_bboxes_ignore.append(bbox)\n",
    "\n",
    "            data_anno = dict(\n",
    "                bboxes=np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n",
    "                labels=np.array(gt_labels, dtype=np.long),\n",
    "                bboxes_ignore=np.array(gt_bboxes_ignore,\n",
    "                                       dtype=np.float32).reshape(-1, 4),\n",
    "                labels_ignore=np.array(gt_labels_ignore, dtype=np.long))\n",
    "\n",
    "            data_info.update(ann=data_anno)\n",
    "            data_infos.append(data_info)\n",
    "\n",
    "        return data_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1632899105503,
     "user": {
      "displayName": "장경희",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05148120440289478711"
     },
     "user_tz": -540
    },
    "id": "BZaUFnqNj0AD"
   },
   "outputs": [],
   "source": [
    "config_file = '/content/mmdetection/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py'\n",
    "checkpoint_file = '/content/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1632899110118,
     "user": {
      "displayName": "장경희",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05148120440289478711"
     },
     "user_tz": -540
    },
    "id": "t3Zh5NZPP4BP",
    "outputId": "ed40695d-388d-4fe8-b2be-a16bedc309c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 163376\n",
      "drwxr-xr-x  2 root root      4096 Sep 29 06:33 .\n",
      "drwxr-xr-x 20 root root      4096 Sep 29 06:54 ..\n",
      "-rw-r--r--  1 root root 167287506 Aug 28  2020 faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n"
     ]
    }
   ],
   "source": [
    "!ls -la /content/mmdetection/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1632899113475,
     "user": {
      "displayName": "장경희",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05148120440289478711"
     },
     "user_tz": -540
    },
    "id": "IYPlOKzuQBZl"
   },
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "cfg = Config.fromfile(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N9vD2um_QcDb"
   },
   "outputs": [],
   "source": [
    "print(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 839,
     "status": "ok",
     "timestamp": 1632899325318,
     "user": {
      "displayName": "장경희",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05148120440289478711"
     },
     "user_tz": -540
    },
    "id": "SMtWwhilQemb",
    "outputId": "0313acb7-dafe-4bcc-85dc-022038fbe01b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='FasterRCNN',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=True,\n",
      "        style='pytorch',\n",
      "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='StandardRoIHead',\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=dict(\n",
      "            type='Shared2FCBBoxHead',\n",
      "            in_channels=256,\n",
      "            fc_out_channels=1024,\n",
      "            roi_feat_size=7,\n",
      "            num_classes=3,\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "            reg_class_agnostic=False,\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
      "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "        train_cfg=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                min_pos_iou=0.5,\n",
      "                match_low_quality=False,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=True),\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        test_cfg=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100),\n",
      "        pretrained=None),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=-1,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                min_pos_iou=0.5,\n",
      "                match_low_quality=False,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=True),\n",
      "            pos_weight=-1,\n",
      "            debug=False)),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100)))\n",
      "dataset_type = 'KittiTinyDataset'\n",
      "data_root = '/content/kitti_tiny/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1333, 800),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='KittiTinyDataset',\n",
      "        ann_file='train.txt',\n",
      "        img_prefix='training/image_2',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ],\n",
      "        data_root='/content/kitti_tiny/'),\n",
      "    val=dict(\n",
      "        type='KittiTinyDataset',\n",
      "        ann_file='val.txt',\n",
      "        img_prefix='training/image_2',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        data_root='/content/kitti_tiny/'),\n",
      "    test=dict(\n",
      "        type='KittiTinyDataset',\n",
      "        ann_file='train.txt',\n",
      "        img_prefix='training/image_2',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        data_root='/content/kitti_tiny/'))\n",
      "evaluation = dict(interval=12, metric='mAP')\n",
      "optimizer = dict(type='SGD', lr=0.0025, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None, type='OptimizerHook')\n",
      "lr_config = dict(\n",
      "    warmup=None,\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11],\n",
      "    type='StepLrUpdaterHook',\n",
      "    policy='step')\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=12)\n",
      "checkpoint_config = dict(interval=12, type='CheckpointHook')\n",
      "log_config = dict(interval=10, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "work_dir = './tutorial_exps'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'KittiTinyDataset'\n",
    "cfg.data_root = '/content/kitti_tiny/'\n",
    "\n",
    "cfg.data.test.type = 'KittiTinyDataset'\n",
    "cfg.data.test.data_root = '/content/kitti_tiny/'\n",
    "cfg.data.test.ann_file = 'train.txt'\n",
    "cfg.data.test.img_prefix = 'training/image_2'\n",
    "\n",
    "cfg.data.train.type = 'KittiTinyDataset'\n",
    "cfg.data.train.data_root = '/content/kitti_tiny/'\n",
    "cfg.data.train.ann_file = 'train.txt'\n",
    "cfg.data.train.img_prefix = 'training/image_2'\n",
    "\n",
    "cfg.data.val.type = 'KittiTinyDataset'\n",
    "cfg.data.val.data_root = '/content/kitti_tiny/'\n",
    "cfg.data.val.ann_file = 'val.txt'\n",
    "cfg.data.val.img_prefix = 'training/image_2'\n",
    "\n",
    "# modify num classes of the model in box head\n",
    "cfg.model.roi_head.bbox_head.num_classes = 3\n",
    "# We can still use the pre-trained Mask RCNN model though we do not need to\n",
    "# use the mask branch\n",
    "cfg.load_from = 'checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './tutorial_exps'\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.optimizer.lr = 0.02 / 8\n",
    "cfg.lr_config.warmup = None\n",
    "cfg.log_config.interval = 10\n",
    "\n",
    "cfg.lr_config.policy = 'step'\n",
    "\n",
    "# Change the evaluation metric since we use customized dataset.\n",
    "cfg.evaluation.metric = 'mAP'\n",
    "# We can set the evaluation interval to reduce the evaluation times\n",
    "cfg.evaluation.interval = 12\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 12\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1632899327763,
     "user": {
      "displayName": "장경희",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05148120440289478711"
     },
     "user_tz": -540
    },
    "id": "eqalIRU-SqhL"
   },
   "outputs": [],
   "source": [
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1632899331674,
     "user": {
      "displayName": "장경희",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05148120440289478711"
     },
     "user_tz": -540
    },
    "id": "xAxk1chPWAXH",
    "outputId": "1a1fabd6-691d-480f-f20f-8d4a83d84ebc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 380,
     "status": "ok",
     "timestamp": 1632899333334,
     "user": {
      "displayName": "장경희",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05148120440289478711"
     },
     "user_tz": -540
    },
    "id": "giQst0uOSrA8",
    "outputId": "de8c4624-09f4-464a-f95b-5b3026ccf52b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.ann_file :  /content/kitti_tiny/train.txt\n",
      "self.img_prefix:  /content/kitti_tiny/training/image_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/mmdet-2.17.0-py3.7.egg/mmdet/datasets/custom.py:157: UserWarning: CustomDataset does not support filtering empty gt images.\n",
      "  'CustomDataset does not support filtering empty gt images.')\n"
     ]
    }
   ],
   "source": [
    "#train용 데이터 셋 생성\n",
    "\n",
    "datasets = [build_dataset(cfg.data.train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 349,
     "status": "ok",
     "timestamp": 1632899336449,
     "user": {
      "displayName": "장경희",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05148120440289478711"
     },
     "user_tz": -540
    },
    "id": "57AIy0oHTRnF",
    "outputId": "b3086b4f-359f-4645-b0dc-43543e1573bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " KittiTinyDataset Train dataset with number of images 50, and instance counts: \n",
       " +----------+-------+----------------+-------+-------------+-------+----------+-------+----------+-------+\n",
       " | category | count | category       | count | category    | count | category | count | category | count |\n",
       " +----------+-------+----------------+-------+-------------+-------+----------+-------+----------+-------+\n",
       " |          |       |                |       |             |       |          |       |          |       |\n",
       " | 0 [Car]  | 147   | 1 [Pedestrian] | 23    | 2 [Cyclist] | 7     |          |       |          |       |\n",
       " +----------+-------+----------------+-------+-------------+-------+----------+-------+----------+-------+]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1632899337591,
     "user": {
      "displayName": "장경희",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05148120440289478711"
     },
     "user_tz": -540
    },
    "id": "K24usWkETlXc",
    "outputId": "c6145977-3cd2-4fa0-a2ed-076e0ba2b973"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Car', 'Pedestrian', 'Cyclist')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0].CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 551,
     "status": "ok",
     "timestamp": 1632899339550,
     "user": {
      "displayName": "장경희",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05148120440289478711"
     },
     "user_tz": -540
    },
    "id": "ojd0c7mjTuy_",
    "outputId": "12b157c1-f3b4-428c-b159-d2023c1186cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/mmdet-2.17.0-py3.7.egg/mmdet/core/anchor/builder.py:17: UserWarning: ``build_anchor_generator`` would be deprecated soon, please use ``build_prior_generator`` \n",
      "  '``build_anchor_generator`` would be deprecated soon, please use '\n"
     ]
    }
   ],
   "source": [
    "model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg') )\n",
    "model.CLASSES = datasets[0].CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1632899340907,
     "user": {
      "displayName": "장경희",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05148120440289478711"
     },
     "user_tz": -540
    },
    "id": "kMtOJebvWf2U",
    "outputId": "01c81fab-f50b-424d-da56-c7de97f69018"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/mmdetection\n"
     ]
    }
   ],
   "source": [
    "%cd mmdetection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 99712,
     "status": "ok",
     "timestamp": 1632899442203,
     "user": {
      "displayName": "장경희",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05148120440289478711"
     },
     "user_tz": -540
    },
    "id": "seQPCJktUWEb",
    "outputId": "552ec683-1bd9-46f7-fe2b-c145378b3eec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-29 07:10:23,867 - mmdet - INFO - load checkpoint from checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n",
      "2021-09-29 07:10:23,869 - mmdet - INFO - Use load_from_local loader\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.ann_file :  /content/kitti_tiny/val.txt\n",
      "self.img_prefix:  /content/kitti_tiny/training/image_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-29 07:10:23,999 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([4, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([4]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([12, 1024]).\n",
      "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([12]).\n",
      "2021-09-29 07:10:24,003 - mmdet - INFO - Start running, host: root@43665bed83ab, work_dir: /content/mmdetection/tutorial_exps\n",
      "2021-09-29 07:10:24,004 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2021-09-29 07:10:24,006 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/usr/local/lib/python3.7/dist-packages/mmdet-2.17.0-py3.7.egg/mmdet/core/anchor/anchor_generator.py:324: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n",
      "  warnings.warn('``grid_anchors`` would be deprecated soon. '\n",
      "/usr/local/lib/python3.7/dist-packages/mmdet-2.17.0-py3.7.egg/mmdet/core/anchor/anchor_generator.py:361: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n",
      "  '``single_level_grid_anchors`` would be deprecated soon. '\n",
      "2021-09-29 07:10:28,653 - mmdet - INFO - Epoch [1][10/25]\tlr: 2.500e-03, eta: 0:02:13, time: 0.459, data_time: 0.221, memory: 2389, loss_rpn_cls: 0.0317, loss_rpn_bbox: 0.0180, loss_cls: 0.5668, acc: 84.0430, loss_bbox: 0.4012, loss: 1.0176\n",
      "2021-09-29 07:10:30,937 - mmdet - INFO - Epoch [1][20/25]\tlr: 2.500e-03, eta: 0:01:36, time: 0.228, data_time: 0.009, memory: 2389, loss_rpn_cls: 0.0234, loss_rpn_bbox: 0.0126, loss_cls: 0.1950, acc: 93.9160, loss_bbox: 0.3166, loss: 0.5476\n",
      "2021-09-29 07:10:36,515 - mmdet - INFO - Epoch [2][10/25]\tlr: 2.500e-03, eta: 0:01:25, time: 0.440, data_time: 0.218, memory: 2389, loss_rpn_cls: 0.0159, loss_rpn_bbox: 0.0154, loss_cls: 0.1620, acc: 94.7852, loss_bbox: 0.2761, loss: 0.4694\n",
      "2021-09-29 07:10:38,822 - mmdet - INFO - Epoch [2][20/25]\tlr: 2.500e-03, eta: 0:01:16, time: 0.231, data_time: 0.010, memory: 2389, loss_rpn_cls: 0.0124, loss_rpn_bbox: 0.0123, loss_cls: 0.1451, acc: 94.3750, loss_bbox: 0.2205, loss: 0.3903\n",
      "2021-09-29 07:10:44,392 - mmdet - INFO - Epoch [3][10/25]\tlr: 2.500e-03, eta: 0:01:11, time: 0.438, data_time: 0.217, memory: 2389, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0113, loss_cls: 0.1018, acc: 96.3477, loss_bbox: 0.1667, loss: 0.2867\n",
      "2021-09-29 07:10:46,708 - mmdet - INFO - Epoch [3][20/25]\tlr: 2.500e-03, eta: 0:01:06, time: 0.232, data_time: 0.009, memory: 2389, loss_rpn_cls: 0.0081, loss_rpn_bbox: 0.0120, loss_cls: 0.1560, acc: 93.9941, loss_bbox: 0.2608, loss: 0.4368\n",
      "2021-09-29 07:10:52,314 - mmdet - INFO - Epoch [4][10/25]\tlr: 2.500e-03, eta: 0:01:02, time: 0.440, data_time: 0.217, memory: 2389, loss_rpn_cls: 0.0070, loss_rpn_bbox: 0.0148, loss_cls: 0.1313, acc: 94.7949, loss_bbox: 0.2276, loss: 0.3807\n",
      "2021-09-29 07:10:54,638 - mmdet - INFO - Epoch [4][20/25]\tlr: 2.500e-03, eta: 0:00:58, time: 0.232, data_time: 0.010, memory: 2389, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0124, loss_cls: 0.1247, acc: 95.2930, loss_bbox: 0.2077, loss: 0.3491\n",
      "2021-09-29 07:11:00,250 - mmdet - INFO - Epoch [5][10/25]\tlr: 2.500e-03, eta: 0:00:54, time: 0.442, data_time: 0.217, memory: 2389, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0097, loss_cls: 0.1068, acc: 96.0449, loss_bbox: 0.1976, loss: 0.3195\n",
      "2021-09-29 07:11:02,571 - mmdet - INFO - Epoch [5][20/25]\tlr: 2.500e-03, eta: 0:00:50, time: 0.232, data_time: 0.010, memory: 2389, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0118, loss_cls: 0.1054, acc: 95.8594, loss_bbox: 0.1720, loss: 0.2938\n",
      "2021-09-29 07:11:08,224 - mmdet - INFO - Epoch [6][10/25]\tlr: 2.500e-03, eta: 0:00:46, time: 0.446, data_time: 0.219, memory: 2389, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0093, loss_cls: 0.0840, acc: 97.0605, loss_bbox: 0.1654, loss: 0.2629\n",
      "2021-09-29 07:11:10,568 - mmdet - INFO - Epoch [6][20/25]\tlr: 2.500e-03, eta: 0:00:43, time: 0.234, data_time: 0.010, memory: 2389, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0098, loss_cls: 0.0955, acc: 96.4355, loss_bbox: 0.1811, loss: 0.2910\n",
      "2021-09-29 07:11:16,224 - mmdet - INFO - Epoch [7][10/25]\tlr: 2.500e-03, eta: 0:00:39, time: 0.444, data_time: 0.218, memory: 2389, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0098, loss_cls: 0.0832, acc: 97.0020, loss_bbox: 0.1594, loss: 0.2564\n",
      "2021-09-29 07:11:18,560 - mmdet - INFO - Epoch [7][20/25]\tlr: 2.500e-03, eta: 0:00:36, time: 0.234, data_time: 0.010, memory: 2389, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0119, loss_cls: 0.0956, acc: 96.3867, loss_bbox: 0.1766, loss: 0.2862\n",
      "2021-09-29 07:11:24,218 - mmdet - INFO - Epoch [8][10/25]\tlr: 2.500e-03, eta: 0:00:32, time: 0.444, data_time: 0.218, memory: 2389, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0088, loss_cls: 0.0747, acc: 97.0215, loss_bbox: 0.1411, loss: 0.2265\n",
      "2021-09-29 07:11:26,552 - mmdet - INFO - Epoch [8][20/25]\tlr: 2.500e-03, eta: 0:00:29, time: 0.233, data_time: 0.009, memory: 2389, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0091, loss_cls: 0.0827, acc: 96.8457, loss_bbox: 0.1648, loss: 0.2587\n",
      "2021-09-29 07:11:32,195 - mmdet - INFO - Epoch [9][10/25]\tlr: 2.500e-04, eta: 0:00:25, time: 0.443, data_time: 0.218, memory: 2389, loss_rpn_cls: 0.0011, loss_rpn_bbox: 0.0088, loss_cls: 0.0696, acc: 97.4707, loss_bbox: 0.1333, loss: 0.2128\n",
      "2021-09-29 07:11:34,536 - mmdet - INFO - Epoch [9][20/25]\tlr: 2.500e-04, eta: 0:00:22, time: 0.234, data_time: 0.009, memory: 2389, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0076, loss_cls: 0.0670, acc: 97.2168, loss_bbox: 0.1285, loss: 0.2053\n",
      "2021-09-29 07:11:40,200 - mmdet - INFO - Epoch [10][10/25]\tlr: 2.500e-04, eta: 0:00:18, time: 0.444, data_time: 0.217, memory: 2389, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0089, loss_cls: 0.0744, acc: 97.0898, loss_bbox: 0.1422, loss: 0.2295\n",
      "2021-09-29 07:11:42,537 - mmdet - INFO - Epoch [10][20/25]\tlr: 2.500e-04, eta: 0:00:15, time: 0.234, data_time: 0.010, memory: 2389, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0065, loss_cls: 0.0646, acc: 97.4219, loss_bbox: 0.1253, loss: 0.1981\n",
      "2021-09-29 07:11:48,168 - mmdet - INFO - Epoch [11][10/25]\tlr: 2.500e-04, eta: 0:00:11, time: 0.442, data_time: 0.217, memory: 2389, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0079, loss_cls: 0.0757, acc: 97.2656, loss_bbox: 0.1308, loss: 0.2166\n",
      "2021-09-29 07:11:50,520 - mmdet - INFO - Epoch [11][20/25]\tlr: 2.500e-04, eta: 0:00:08, time: 0.235, data_time: 0.010, memory: 2389, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0089, loss_cls: 0.0669, acc: 97.6562, loss_bbox: 0.1334, loss: 0.2120\n",
      "2021-09-29 07:11:56,181 - mmdet - INFO - Epoch [12][10/25]\tlr: 2.500e-05, eta: 0:00:04, time: 0.444, data_time: 0.218, memory: 2389, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0064, loss_cls: 0.0634, acc: 97.4609, loss_bbox: 0.1193, loss: 0.1915\n",
      "2021-09-29 07:11:58,512 - mmdet - INFO - Epoch [12][20/25]\tlr: 2.500e-05, eta: 0:00:01, time: 0.233, data_time: 0.009, memory: 2389, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0063, loss_cls: 0.0611, acc: 97.5195, loss_bbox: 0.0994, loss: 0.1697\n",
      "2021-09-29 07:11:59,659 - mmdet - INFO - Saving checkpoint at 12 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 25/25, 15.9 task/s, elapsed: 2s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-29 07:12:02,012 - mmdet - INFO - \n",
      "+------------+-----+------+--------+-------+\n",
      "| class      | gts | dets | recall | ap    |\n",
      "+------------+-----+------+--------+-------+\n",
      "| Car        | 62  | 147  | 0.903  | 0.819 |\n",
      "| Pedestrian | 13  | 54   | 0.923  | 0.796 |\n",
      "| Cyclist    | 7   | 61   | 0.571  | 0.095 |\n",
      "+------------+-----+------+--------+-------+\n",
      "| mAP        |     |      |        | 0.570 |\n",
      "+------------+-----+------+--------+-------+\n",
      "2021-09-29 07:12:02,015 - mmdet - INFO - Epoch(val) [12][25]\tAP50: 0.5700, mAP: 0.5700\n"
     ]
    }
   ],
   "source": [
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_detector(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 852974,
     "status": "ok",
     "timestamp": 1632902113030,
     "user": {
      "displayName": "장경희",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05148120440289478711"
     },
     "user_tz": -540
    },
    "id": "OP3iPM5jYElT",
    "outputId": "82747871-7dc2-49dd-ce19-74d06f567272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                                  ] 0/2939, elapsed: 0s, ETA:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/mmdet-2.17.0-py3.7.egg/mmdet/datasets/utils.py:69: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n",
      "  'data pipeline in your config file.', UserWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/mmdet-2.17.0-py3.7.egg/mmdet/core/anchor/anchor_generator.py:324: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n",
      "  warnings.warn('``grid_anchors`` would be deprecated soon. '\n",
      "/usr/local/lib/python3.7/dist-packages/mmdet-2.17.0-py3.7.egg/mmdet/core/anchor/anchor_generator.py:361: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n",
      "  '``single_level_grid_anchors`` would be deprecated soon. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2939/2939, 3.4 task/s, elapsed: 853s, ETA:     0s\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mmcv\n",
    "\n",
    "model.cfg = cfg\n",
    "\n",
    "video_reader = mmcv.VideoReader(\"/content/data/songdo_driving_Trim2.mp4\")\n",
    "video_writer = None\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_writer = cv2.VideoWriter(\"/content/data/songdo_driving_Trim2_out.mp4\", fourcc, \n",
    "                               video_reader.fps, (video_reader.width, video_reader.height))\n",
    "\n",
    "for frame in mmcv.track_iter_progress(video_reader):\n",
    "  result = inference_detector(model, frame)\n",
    "  frame = model.show_result(frame, result, score_thr=0.4)\n",
    "  video_writer.write(frame)\n",
    "\n",
    "if video_writer:\n",
    "  video_writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eegf1jSDfwyd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOh9oC9kwGolpfZbnp6XLRH",
   "machine_shape": "hm",
   "name": "Object Detection (kitti tiny).ipynb의 사본",
   "provenance": [
    {
     "file_id": "1-F_yXuMeA579CwYETFOOeM5fhDJO77GY",
     "timestamp": 1632902153362
    },
    {
     "file_id": "1x3bZgUN40Qs1Ilck8RCYBZ1asVEQ7Bax",
     "timestamp": 1632893576028
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
