{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Object Detection (kitti tiny).ipynb의 사본","provenance":[{"file_id":"1-F_yXuMeA579CwYETFOOeM5fhDJO77GY","timestamp":1632902153362},{"file_id":"1x3bZgUN40Qs1Ilck8RCYBZ1asVEQ7Bax","timestamp":1632893576028}],"machine_shape":"hm","authorship_tag":"ABX9TyOh9oC9kwGolpfZbnp6XLRH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8BY3DxMXY7AP","executionInfo":{"status":"ok","timestamp":1632894580665,"user_tz":-540,"elapsed":868538,"user":{"displayName":"장경희","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05148120440289478711"}},"outputId":"75fd40ee-b927-41b0-ad36-94251aa3cd28"},"source":["!pip install mmcv-full"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting mmcv-full\n","  Downloading mmcv-full-1.3.14.tar.gz (324 kB)\n","\u001b[K     |████████████████████████████████| 324 kB 8.3 MB/s \n","\u001b[?25hCollecting addict\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (21.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (7.1.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (3.13)\n","Collecting yapf\n","  Downloading yapf-0.31.0-py2.py3-none-any.whl (185 kB)\n","\u001b[K     |████████████████████████████████| 185 kB 67.1 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mmcv-full) (2.4.7)\n","Building wheels for collected packages: mmcv-full\n","  Building wheel for mmcv-full (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mmcv-full: filename=mmcv_full-1.3.14-cp37-cp37m-linux_x86_64.whl size=31614925 sha256=204beb9bca2c4a58886e1738b1bd8e24ebcb4ee4042608d6a2d6a1789ecdf2e2\n","  Stored in directory: /root/.cache/pip/wheels/5e/54/62/69c99dc3c9937bca64126f81cbe315ae6c8e6e98c43fa7392d\n","Successfully built mmcv-full\n","Installing collected packages: yapf, addict, mmcv-full\n","Successfully installed addict-2.4.0 mmcv-full-1.3.14 yapf-0.31.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0H7MCCFCajM4","executionInfo":{"status":"ok","timestamp":1632894582784,"user_tz":-540,"elapsed":2152,"user":{"displayName":"장경희","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05148120440289478711"}},"outputId":"1905694e-e76c-4871-dae3-a8caab1004ac"},"source":["!git clone https://github.com/open-mmlab/mmdetection.git"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'mmdetection'...\n","remote: Enumerating objects: 21083, done.\u001b[K\n","remote: Total 21083 (delta 0), reused 0 (delta 0), pack-reused 21083\u001b[K\n","Receiving objects: 100% (21083/21083), 24.81 MiB | 30.57 MiB/s, done.\n","Resolving deltas: 100% (14743/14743), done.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BvxucyZZes_C","executionInfo":{"status":"ok","timestamp":1632895200712,"user_tz":-540,"elapsed":352,"user":{"displayName":"장경희","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05148120440289478711"}},"outputId":"2db14e16-2ca2-441f-e65c-816a6ef35e56"},"source":["%cd mmdetection"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/mmdetection\n"]}]},{"cell_type":"code","metadata":{"id":"YGhoklrqhAi8"},"source":["!python setup.py install"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pVrjIQmBhfpL","executionInfo":{"status":"ok","timestamp":1632895222018,"user_tz":-540,"elapsed":332,"user":{"displayName":"장경희","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05148120440289478711"}}},"source":["!mkdir checkpoints"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nzthLAXCiH17","executionInfo":{"status":"ok","timestamp":1632897132686,"user_tz":-540,"elapsed":15127,"user":{"displayName":"장경희","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05148120440289478711"}},"outputId":"787b32fd-b6a6-4889-e13f-2dbfb7ed551b"},"source":["!wget -O /content/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-09-29 06:33:18--  https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n","Resolving download.openmmlab.com (download.openmmlab.com)... 47.88.36.78\n","Connecting to download.openmmlab.com (download.openmmlab.com)|47.88.36.78|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 167287506 (160M) [application/octet-stream]\n","Saving to: ‘/content/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth’\n","\n","/content/mmdetectio 100%[===================>] 159.54M  13.0MB/s    in 14s     \n","\n","2021-09-29 06:33:33 (11.5 MB/s) - ‘/content/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth’ saved [167287506/167287506]\n","\n"]}]},{"cell_type":"code","metadata":{"id":"dBlthlYkksUk","executionInfo":{"status":"ok","timestamp":1632899094214,"user_tz":-540,"elapsed":7828,"user":{"displayName":"장경희","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05148120440289478711"}}},"source":["from mmdet.apis import init_detector, inference_detector, show_result_pyplot"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"zwvbTsQ-5hnb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632895357526,"user_tz":-540,"elapsed":3020,"user":{"displayName":"장경희","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05148120440289478711"}},"outputId":"3f48190d-41b6-4d2f-8aef-4cdf807994cd"},"source":["# download, decompress the data\n","!wget https://download.openmmlab.com/mmdetection/data/kitti_tiny.zip\n","!unzip kitti_tiny.zip > /dev/null"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-09-29 06:03:55--  https://download.openmmlab.com/mmdetection/data/kitti_tiny.zip\n","Resolving download.openmmlab.com (download.openmmlab.com)... 47.88.36.78\n","Connecting to download.openmmlab.com (download.openmmlab.com)|47.88.36.78|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 6918271 (6.6M) [application/zip]\n","Saving to: ‘kitti_tiny.zip’\n","\n","kitti_tiny.zip      100%[===================>]   6.60M  4.15MB/s    in 1.6s    \n","\n","2021-09-29 06:03:58 (4.15 MB/s) - ‘kitti_tiny.zip’ saved [6918271/6918271]\n","\n"]}]},{"cell_type":"code","metadata":{"id":"g0q11t4VEpr9"},"source":["#CLASSES = ('Car', 'Van', 'Truck', 'Pedestrian', 'Person_sitting', 'Cyclist', 'Tram', 'Misc', 'DontCare')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Zq9WX_IOKHk","executionInfo":{"status":"ok","timestamp":1632899102043,"user_tz":-540,"elapsed":330,"user":{"displayName":"장경희","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05148120440289478711"}}},"source":["import copy\n","import os.path as osp\n","\n","import mmcv\n","import numpy as np\n","\n","from mmdet.datasets.builder import DATASETS\n","from mmdet.datasets.custom import CustomDataset\n","\n","@DATASETS.register_module(force=True)\n","class KittiTinyDataset(CustomDataset):\n","\n","    CLASSES = ('Car', 'Pedestrian', 'Cyclist')\n","    \n","    ### self.ann_file : /content/kitti_tiny/train.txt\n","    ### self.img_prefix : /content/kitti_tiny/training/image_2\n","    ### ann_file : /content/kitti_tiny/train.txt\n","\n","    def load_annotations(self, ann_file):\n","        print(\"self.ann_file : \", self.ann_file)\n","        print(\"self.img_prefix: \", self.img_prefix)\n","\n","        cat2label = {k: i for i, k in enumerate(self.CLASSES)}\n","        # load image list from file\n","        image_list = mmcv.list_from_file(self.ann_file)\n","    \n","        data_infos = []\n","        # convert annotations to middle format\n","        for image_id in image_list:\n","            filename = f'{self.img_prefix}/{image_id}.jpeg'\n","            image = mmcv.imread(filename)\n","            height, width = image.shape[:2]\n","    \n","            data_info = dict(filename=f'{image_id}.jpeg', width=width, height=height)\n","    \n","            # load annotations\n","            label_prefix = self.img_prefix.replace('image_2', 'label_2')\n","            lines = mmcv.list_from_file(osp.join(label_prefix, f'{image_id}.txt'))\n","    \n","            content = [line.strip().split(' ') for line in lines]\n","            bbox_names = [x[0] for x in content]\n","            bboxes = [[float(info) for info in x[4:8]] for x in content]\n","    \n","            gt_bboxes = []\n","            gt_labels = []\n","            gt_bboxes_ignore = []\n","            gt_labels_ignore = []\n","    \n","            # filter 'DontCare'\n","            for bbox_name, bbox in zip(bbox_names, bboxes):\n","                if bbox_name in cat2label:\n","                    gt_labels.append(cat2label[bbox_name])\n","                    gt_bboxes.append(bbox)\n","                else:\n","                    gt_labels_ignore.append(-1)\n","                    gt_bboxes_ignore.append(bbox)\n","\n","            data_anno = dict(\n","                bboxes=np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n","                labels=np.array(gt_labels, dtype=np.long),\n","                bboxes_ignore=np.array(gt_bboxes_ignore,\n","                                       dtype=np.float32).reshape(-1, 4),\n","                labels_ignore=np.array(gt_labels_ignore, dtype=np.long))\n","\n","            data_info.update(ann=data_anno)\n","            data_infos.append(data_info)\n","\n","        return data_infos"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"BZaUFnqNj0AD","executionInfo":{"status":"ok","timestamp":1632899105503,"user_tz":-540,"elapsed":328,"user":{"displayName":"장경희","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05148120440289478711"}}},"source":["config_file = '/content/mmdetection/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py'\n","checkpoint_file = '/content/mmdetection/checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t3Zh5NZPP4BP","executionInfo":{"status":"ok","timestamp":1632899110118,"user_tz":-540,"elapsed":337,"user":{"displayName":"장경희","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05148120440289478711"}},"outputId":"ed40695d-388d-4fe8-b2be-a16bedc309c8"},"source":["!ls -la /content/mmdetection/checkpoints/"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["total 163376\n","drwxr-xr-x  2 root root      4096 Sep 29 06:33 .\n","drwxr-xr-x 20 root root      4096 Sep 29 06:54 ..\n","-rw-r--r--  1 root root 167287506 Aug 28  2020 faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n"]}]},{"cell_type":"code","metadata":{"id":"IYPlOKzuQBZl","executionInfo":{"status":"ok","timestamp":1632899113475,"user_tz":-540,"elapsed":336,"user":{"displayName":"장경희","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05148120440289478711"}}},"source":["from mmcv import Config\n","cfg = Config.fromfile(config_file)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"N9vD2um_QcDb"},"source":["print(cfg.pretty_text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SMtWwhilQemb","executionInfo":{"status":"ok","timestamp":1632899325318,"user_tz":-540,"elapsed":839,"user":{"displayName":"장경희","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05148120440289478711"}},"outputId":"0313acb7-dafe-4bcc-85dc-022038fbe01b"},"source":["from mmdet.apis import set_random_seed\n","\n","# Modify dataset type and path\n","cfg.dataset_type = 'KittiTinyDataset'\n","cfg.data_root = '/content/kitti_tiny/'\n","\n","cfg.data.test.type = 'KittiTinyDataset'\n","cfg.data.test.data_root = '/content/kitti_tiny/'\n","cfg.data.test.ann_file = 'train.txt'\n","cfg.data.test.img_prefix = 'training/image_2'\n","\n","cfg.data.train.type = 'KittiTinyDataset'\n","cfg.data.train.data_root = '/content/kitti_tiny/'\n","cfg.data.train.ann_file = 'train.txt'\n","cfg.data.train.img_prefix = 'training/image_2'\n","\n","cfg.data.val.type = 'KittiTinyDataset'\n","cfg.data.val.data_root = '/content/kitti_tiny/'\n","cfg.data.val.ann_file = 'val.txt'\n","cfg.data.val.img_prefix = 'training/image_2'\n","\n","# modify num classes of the model in box head\n","cfg.model.roi_head.bbox_head.num_classes = 3\n","# We can still use the pre-trained Mask RCNN model though we do not need to\n","# use the mask branch\n","cfg.load_from = 'checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n","\n","# Set up working dir to save files and logs.\n","cfg.work_dir = './tutorial_exps'\n","\n","# The original learning rate (LR) is set for 8-GPU training.\n","# We divide it by 8 since we only use one GPU.\n","cfg.optimizer.lr = 0.02 / 8\n","cfg.lr_config.warmup = None\n","cfg.log_config.interval = 10\n","\n","cfg.lr_config.policy = 'step'\n","\n","# Change the evaluation metric since we use customized dataset.\n","cfg.evaluation.metric = 'mAP'\n","# We can set the evaluation interval to reduce the evaluation times\n","cfg.evaluation.interval = 12\n","# We can set the checkpoint saving interval to reduce the storage cost\n","cfg.checkpoint_config.interval = 12\n","\n","# Set seed thus the results are more reproducible\n","cfg.seed = 0\n","set_random_seed(0, deterministic=False)\n","cfg.gpu_ids = range(1)\n","\n","\n","# We can initialize the logger for training and have a look\n","# at the final config used for training\n","print(f'Config:\\n{cfg.pretty_text}')"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Config:\n","model = dict(\n","    type='FasterRCNN',\n","    backbone=dict(\n","        type='ResNet',\n","        depth=50,\n","        num_stages=4,\n","        out_indices=(0, 1, 2, 3),\n","        frozen_stages=1,\n","        norm_cfg=dict(type='BN', requires_grad=True),\n","        norm_eval=True,\n","        style='pytorch',\n","        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n","    neck=dict(\n","        type='FPN',\n","        in_channels=[256, 512, 1024, 2048],\n","        out_channels=256,\n","        num_outs=5),\n","    rpn_head=dict(\n","        type='RPNHead',\n","        in_channels=256,\n","        feat_channels=256,\n","        anchor_generator=dict(\n","            type='AnchorGenerator',\n","            scales=[8],\n","            ratios=[0.5, 1.0, 2.0],\n","            strides=[4, 8, 16, 32, 64]),\n","        bbox_coder=dict(\n","            type='DeltaXYWHBBoxCoder',\n","            target_means=[0.0, 0.0, 0.0, 0.0],\n","            target_stds=[1.0, 1.0, 1.0, 1.0]),\n","        loss_cls=dict(\n","            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n","        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n","    roi_head=dict(\n","        type='StandardRoIHead',\n","        bbox_roi_extractor=dict(\n","            type='SingleRoIExtractor',\n","            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n","            out_channels=256,\n","            featmap_strides=[4, 8, 16, 32]),\n","        bbox_head=dict(\n","            type='Shared2FCBBoxHead',\n","            in_channels=256,\n","            fc_out_channels=1024,\n","            roi_feat_size=7,\n","            num_classes=3,\n","            bbox_coder=dict(\n","                type='DeltaXYWHBBoxCoder',\n","                target_means=[0.0, 0.0, 0.0, 0.0],\n","                target_stds=[0.1, 0.1, 0.2, 0.2]),\n","            reg_class_agnostic=False,\n","            loss_cls=dict(\n","                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n","            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n","        train_cfg=dict(\n","            assigner=dict(\n","                type='MaxIoUAssigner',\n","                pos_iou_thr=0.5,\n","                neg_iou_thr=0.5,\n","                min_pos_iou=0.5,\n","                match_low_quality=False,\n","                ignore_iof_thr=-1),\n","            sampler=dict(\n","                type='RandomSampler',\n","                num=512,\n","                pos_fraction=0.25,\n","                neg_pos_ub=-1,\n","                add_gt_as_proposals=True),\n","            pos_weight=-1,\n","            debug=False),\n","        test_cfg=dict(\n","            score_thr=0.05,\n","            nms=dict(type='nms', iou_threshold=0.5),\n","            max_per_img=100),\n","        pretrained=None),\n","    train_cfg=dict(\n","        rpn=dict(\n","            assigner=dict(\n","                type='MaxIoUAssigner',\n","                pos_iou_thr=0.7,\n","                neg_iou_thr=0.3,\n","                min_pos_iou=0.3,\n","                match_low_quality=True,\n","                ignore_iof_thr=-1),\n","            sampler=dict(\n","                type='RandomSampler',\n","                num=256,\n","                pos_fraction=0.5,\n","                neg_pos_ub=-1,\n","                add_gt_as_proposals=False),\n","            allowed_border=-1,\n","            pos_weight=-1,\n","            debug=False),\n","        rpn_proposal=dict(\n","            nms_pre=2000,\n","            max_per_img=1000,\n","            nms=dict(type='nms', iou_threshold=0.7),\n","            min_bbox_size=0),\n","        rcnn=dict(\n","            assigner=dict(\n","                type='MaxIoUAssigner',\n","                pos_iou_thr=0.5,\n","                neg_iou_thr=0.5,\n","                min_pos_iou=0.5,\n","                match_low_quality=False,\n","                ignore_iof_thr=-1),\n","            sampler=dict(\n","                type='RandomSampler',\n","                num=512,\n","                pos_fraction=0.25,\n","                neg_pos_ub=-1,\n","                add_gt_as_proposals=True),\n","            pos_weight=-1,\n","            debug=False)),\n","    test_cfg=dict(\n","        rpn=dict(\n","            nms_pre=1000,\n","            max_per_img=1000,\n","            nms=dict(type='nms', iou_threshold=0.7),\n","            min_bbox_size=0),\n","        rcnn=dict(\n","            score_thr=0.05,\n","            nms=dict(type='nms', iou_threshold=0.5),\n","            max_per_img=100)))\n","dataset_type = 'KittiTinyDataset'\n","data_root = '/content/kitti_tiny/'\n","img_norm_cfg = dict(\n","    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n","train_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(type='LoadAnnotations', with_bbox=True),\n","    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n","    dict(type='RandomFlip', flip_ratio=0.5),\n","    dict(\n","        type='Normalize',\n","        mean=[123.675, 116.28, 103.53],\n","        std=[58.395, 57.12, 57.375],\n","        to_rgb=True),\n","    dict(type='Pad', size_divisor=32),\n","    dict(type='DefaultFormatBundle'),\n","    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n","]\n","test_pipeline = [\n","    dict(type='LoadImageFromFile'),\n","    dict(\n","        type='MultiScaleFlipAug',\n","        img_scale=(1333, 800),\n","        flip=False,\n","        transforms=[\n","            dict(type='Resize', keep_ratio=True),\n","            dict(type='RandomFlip'),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='Pad', size_divisor=32),\n","            dict(type='ImageToTensor', keys=['img']),\n","            dict(type='Collect', keys=['img'])\n","        ])\n","]\n","data = dict(\n","    samples_per_gpu=2,\n","    workers_per_gpu=2,\n","    train=dict(\n","        type='KittiTinyDataset',\n","        ann_file='train.txt',\n","        img_prefix='training/image_2',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(type='LoadAnnotations', with_bbox=True),\n","            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n","            dict(type='RandomFlip', flip_ratio=0.5),\n","            dict(\n","                type='Normalize',\n","                mean=[123.675, 116.28, 103.53],\n","                std=[58.395, 57.12, 57.375],\n","                to_rgb=True),\n","            dict(type='Pad', size_divisor=32),\n","            dict(type='DefaultFormatBundle'),\n","            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n","        ],\n","        data_root='/content/kitti_tiny/'),\n","    val=dict(\n","        type='KittiTinyDataset',\n","        ann_file='val.txt',\n","        img_prefix='training/image_2',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(1333, 800),\n","                flip=False,\n","                transforms=[\n","                    dict(type='Resize', keep_ratio=True),\n","                    dict(type='RandomFlip'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[123.675, 116.28, 103.53],\n","                        std=[58.395, 57.12, 57.375],\n","                        to_rgb=True),\n","                    dict(type='Pad', size_divisor=32),\n","                    dict(type='ImageToTensor', keys=['img']),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ],\n","        data_root='/content/kitti_tiny/'),\n","    test=dict(\n","        type='KittiTinyDataset',\n","        ann_file='train.txt',\n","        img_prefix='training/image_2',\n","        pipeline=[\n","            dict(type='LoadImageFromFile'),\n","            dict(\n","                type='MultiScaleFlipAug',\n","                img_scale=(1333, 800),\n","                flip=False,\n","                transforms=[\n","                    dict(type='Resize', keep_ratio=True),\n","                    dict(type='RandomFlip'),\n","                    dict(\n","                        type='Normalize',\n","                        mean=[123.675, 116.28, 103.53],\n","                        std=[58.395, 57.12, 57.375],\n","                        to_rgb=True),\n","                    dict(type='Pad', size_divisor=32),\n","                    dict(type='ImageToTensor', keys=['img']),\n","                    dict(type='Collect', keys=['img'])\n","                ])\n","        ],\n","        data_root='/content/kitti_tiny/'))\n","evaluation = dict(interval=12, metric='mAP')\n","optimizer = dict(type='SGD', lr=0.0025, momentum=0.9, weight_decay=0.0001)\n","optimizer_config = dict(grad_clip=None, type='OptimizerHook')\n","lr_config = dict(\n","    warmup=None,\n","    warmup_iters=500,\n","    warmup_ratio=0.001,\n","    step=[8, 11],\n","    type='StepLrUpdaterHook',\n","    policy='step')\n","runner = dict(type='EpochBasedRunner', max_epochs=12)\n","checkpoint_config = dict(interval=12, type='CheckpointHook')\n","log_config = dict(interval=10, hooks=[dict(type='TextLoggerHook')])\n","custom_hooks = [dict(type='NumClassCheckHook')]\n","dist_params = dict(backend='nccl')\n","log_level = 'INFO'\n","load_from = 'checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'\n","resume_from = None\n","workflow = [('train', 1)]\n","work_dir = './tutorial_exps'\n","seed = 0\n","gpu_ids = range(0, 1)\n","\n"]}]},{"cell_type":"code","metadata":{"id":"eqalIRU-SqhL","executionInfo":{"status":"ok","timestamp":1632899327763,"user_tz":-540,"elapsed":336,"user":{"displayName":"장경희","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05148120440289478711"}}},"source":["from mmdet.datasets import build_dataset\n","from mmdet.models import build_detector\n","from mmdet.apis import train_detector"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xAxk1chPWAXH","executionInfo":{"status":"ok","timestamp":1632899331674,"user_tz":-540,"elapsed":316,"user":{"displayName":"장경희","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05148120440289478711"}},"outputId":"1a1fabd6-691d-480f-f20f-8d4a83d84ebc"},"source":["%cd .."],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"giQst0uOSrA8","executionInfo":{"status":"ok","timestamp":1632899333334,"user_tz":-540,"elapsed":380,"user":{"displayName":"장경희","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05148120440289478711"}},"outputId":"de8c4624-09f4-464a-f95b-5b3026ccf52b"},"source":["#train용 데이터 셋 생성\n","\n","datasets = [build_dataset(cfg.data.train)]"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["self.ann_file :  /content/kitti_tiny/train.txt\n","self.img_prefix:  /content/kitti_tiny/training/image_2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/mmdet-2.17.0-py3.7.egg/mmdet/datasets/custom.py:157: UserWarning: CustomDataset does not support filtering empty gt images.\n","  'CustomDataset does not support filtering empty gt images.')\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"57AIy0oHTRnF","executionInfo":{"status":"ok","timestamp":1632899336449,"user_tz":-540,"elapsed":349,"user":{"displayName":"장경희","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05148120440289478711"}},"outputId":"b3086b4f-359f-4645-b0dc-43543e1573bb"},"source":["datasets"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\n"," KittiTinyDataset Train dataset with number of images 50, and instance counts: \n"," +----------+-------+----------------+-------+-------------+-------+----------+-------+----------+-------+\n"," | category | count | category       | count | category    | count | category | count | category | count |\n"," +----------+-------+----------------+-------+-------------+-------+----------+-------+----------+-------+\n"," |          |       |                |       |             |       |          |       |          |       |\n"," | 0 [Car]  | 147   | 1 [Pedestrian] | 23    | 2 [Cyclist] | 7     |          |       |          |       |\n"," +----------+-------+----------------+-------+-------------+-------+----------+-------+----------+-------+]"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K24usWkETlXc","executionInfo":{"status":"ok","timestamp":1632899337591,"user_tz":-540,"elapsed":6,"user":{"displayName":"장경희","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05148120440289478711"}},"outputId":"c6145977-3cd2-4fa0-a2ed-076e0ba2b973"},"source":["datasets[0].CLASSES"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('Car', 'Pedestrian', 'Cyclist')"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ojd0c7mjTuy_","executionInfo":{"status":"ok","timestamp":1632899339550,"user_tz":-540,"elapsed":551,"user":{"displayName":"장경희","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05148120440289478711"}},"outputId":"12b157c1-f3b4-428c-b159-d2023c1186cb"},"source":["model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg') )\n","model.CLASSES = datasets[0].CLASSES"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/mmdet-2.17.0-py3.7.egg/mmdet/core/anchor/builder.py:17: UserWarning: ``build_anchor_generator`` would be deprecated soon, please use ``build_prior_generator`` \n","  '``build_anchor_generator`` would be deprecated soon, please use '\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kMtOJebvWf2U","executionInfo":{"status":"ok","timestamp":1632899340907,"user_tz":-540,"elapsed":7,"user":{"displayName":"장경희","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05148120440289478711"}},"outputId":"01c81fab-f50b-424d-da56-c7de97f69018"},"source":["%cd mmdetection/"],"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/mmdetection\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"seQPCJktUWEb","executionInfo":{"status":"ok","timestamp":1632899442203,"user_tz":-540,"elapsed":99712,"user":{"displayName":"장경희","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05148120440289478711"}},"outputId":"552ec683-1bd9-46f7-fe2b-c145378b3eec"},"source":["mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n","train_detector(model, datasets, cfg, distributed=False, validate=True)"],"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["2021-09-29 07:10:23,867 - mmdet - INFO - load checkpoint from checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth\n","2021-09-29 07:10:23,869 - mmdet - INFO - Use load_from_local loader\n"]},{"output_type":"stream","name":"stdout","text":["self.ann_file :  /content/kitti_tiny/val.txt\n","self.img_prefix:  /content/kitti_tiny/training/image_2\n"]},{"output_type":"stream","name":"stderr","text":["2021-09-29 07:10:23,999 - mmdet - WARNING - The model and loaded state dict do not match exactly\n","\n","size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([4, 1024]).\n","size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([4]).\n","size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([12, 1024]).\n","size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([12]).\n","2021-09-29 07:10:24,003 - mmdet - INFO - Start running, host: root@43665bed83ab, work_dir: /content/mmdetection/tutorial_exps\n","2021-09-29 07:10:24,004 - mmdet - INFO - Hooks will be executed in the following order:\n","before_run:\n","(VERY_HIGH   ) StepLrUpdaterHook                  \n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_train_epoch:\n","(VERY_HIGH   ) StepLrUpdaterHook                  \n","(NORMAL      ) NumClassCheckHook                  \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_train_iter:\n","(VERY_HIGH   ) StepLrUpdaterHook                  \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n"," -------------------- \n","after_train_iter:\n","(ABOVE_NORMAL) OptimizerHook                      \n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) IterTimerHook                      \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","after_train_epoch:\n","(NORMAL      ) CheckpointHook                     \n","(LOW         ) EvalHook                           \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_val_epoch:\n","(NORMAL      ) NumClassCheckHook                  \n","(LOW         ) IterTimerHook                      \n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","before_val_iter:\n","(LOW         ) IterTimerHook                      \n"," -------------------- \n","after_val_iter:\n","(LOW         ) IterTimerHook                      \n"," -------------------- \n","after_val_epoch:\n","(VERY_LOW    ) TextLoggerHook                     \n"," -------------------- \n","2021-09-29 07:10:24,006 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","/usr/local/lib/python3.7/dist-packages/mmdet-2.17.0-py3.7.egg/mmdet/core/anchor/anchor_generator.py:324: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n","  warnings.warn('``grid_anchors`` would be deprecated soon. '\n","/usr/local/lib/python3.7/dist-packages/mmdet-2.17.0-py3.7.egg/mmdet/core/anchor/anchor_generator.py:361: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n","  '``single_level_grid_anchors`` would be deprecated soon. '\n","2021-09-29 07:10:28,653 - mmdet - INFO - Epoch [1][10/25]\tlr: 2.500e-03, eta: 0:02:13, time: 0.459, data_time: 0.221, memory: 2389, loss_rpn_cls: 0.0317, loss_rpn_bbox: 0.0180, loss_cls: 0.5668, acc: 84.0430, loss_bbox: 0.4012, loss: 1.0176\n","2021-09-29 07:10:30,937 - mmdet - INFO - Epoch [1][20/25]\tlr: 2.500e-03, eta: 0:01:36, time: 0.228, data_time: 0.009, memory: 2389, loss_rpn_cls: 0.0234, loss_rpn_bbox: 0.0126, loss_cls: 0.1950, acc: 93.9160, loss_bbox: 0.3166, loss: 0.5476\n","2021-09-29 07:10:36,515 - mmdet - INFO - Epoch [2][10/25]\tlr: 2.500e-03, eta: 0:01:25, time: 0.440, data_time: 0.218, memory: 2389, loss_rpn_cls: 0.0159, loss_rpn_bbox: 0.0154, loss_cls: 0.1620, acc: 94.7852, loss_bbox: 0.2761, loss: 0.4694\n","2021-09-29 07:10:38,822 - mmdet - INFO - Epoch [2][20/25]\tlr: 2.500e-03, eta: 0:01:16, time: 0.231, data_time: 0.010, memory: 2389, loss_rpn_cls: 0.0124, loss_rpn_bbox: 0.0123, loss_cls: 0.1451, acc: 94.3750, loss_bbox: 0.2205, loss: 0.3903\n","2021-09-29 07:10:44,392 - mmdet - INFO - Epoch [3][10/25]\tlr: 2.500e-03, eta: 0:01:11, time: 0.438, data_time: 0.217, memory: 2389, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0113, loss_cls: 0.1018, acc: 96.3477, loss_bbox: 0.1667, loss: 0.2867\n","2021-09-29 07:10:46,708 - mmdet - INFO - Epoch [3][20/25]\tlr: 2.500e-03, eta: 0:01:06, time: 0.232, data_time: 0.009, memory: 2389, loss_rpn_cls: 0.0081, loss_rpn_bbox: 0.0120, loss_cls: 0.1560, acc: 93.9941, loss_bbox: 0.2608, loss: 0.4368\n","2021-09-29 07:10:52,314 - mmdet - INFO - Epoch [4][10/25]\tlr: 2.500e-03, eta: 0:01:02, time: 0.440, data_time: 0.217, memory: 2389, loss_rpn_cls: 0.0070, loss_rpn_bbox: 0.0148, loss_cls: 0.1313, acc: 94.7949, loss_bbox: 0.2276, loss: 0.3807\n","2021-09-29 07:10:54,638 - mmdet - INFO - Epoch [4][20/25]\tlr: 2.500e-03, eta: 0:00:58, time: 0.232, data_time: 0.010, memory: 2389, loss_rpn_cls: 0.0043, loss_rpn_bbox: 0.0124, loss_cls: 0.1247, acc: 95.2930, loss_bbox: 0.2077, loss: 0.3491\n","2021-09-29 07:11:00,250 - mmdet - INFO - Epoch [5][10/25]\tlr: 2.500e-03, eta: 0:00:54, time: 0.442, data_time: 0.217, memory: 2389, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0097, loss_cls: 0.1068, acc: 96.0449, loss_bbox: 0.1976, loss: 0.3195\n","2021-09-29 07:11:02,571 - mmdet - INFO - Epoch [5][20/25]\tlr: 2.500e-03, eta: 0:00:50, time: 0.232, data_time: 0.010, memory: 2389, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0118, loss_cls: 0.1054, acc: 95.8594, loss_bbox: 0.1720, loss: 0.2938\n","2021-09-29 07:11:08,224 - mmdet - INFO - Epoch [6][10/25]\tlr: 2.500e-03, eta: 0:00:46, time: 0.446, data_time: 0.219, memory: 2389, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0093, loss_cls: 0.0840, acc: 97.0605, loss_bbox: 0.1654, loss: 0.2629\n","2021-09-29 07:11:10,568 - mmdet - INFO - Epoch [6][20/25]\tlr: 2.500e-03, eta: 0:00:43, time: 0.234, data_time: 0.010, memory: 2389, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0098, loss_cls: 0.0955, acc: 96.4355, loss_bbox: 0.1811, loss: 0.2910\n","2021-09-29 07:11:16,224 - mmdet - INFO - Epoch [7][10/25]\tlr: 2.500e-03, eta: 0:00:39, time: 0.444, data_time: 0.218, memory: 2389, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0098, loss_cls: 0.0832, acc: 97.0020, loss_bbox: 0.1594, loss: 0.2564\n","2021-09-29 07:11:18,560 - mmdet - INFO - Epoch [7][20/25]\tlr: 2.500e-03, eta: 0:00:36, time: 0.234, data_time: 0.010, memory: 2389, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0119, loss_cls: 0.0956, acc: 96.3867, loss_bbox: 0.1766, loss: 0.2862\n","2021-09-29 07:11:24,218 - mmdet - INFO - Epoch [8][10/25]\tlr: 2.500e-03, eta: 0:00:32, time: 0.444, data_time: 0.218, memory: 2389, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0088, loss_cls: 0.0747, acc: 97.0215, loss_bbox: 0.1411, loss: 0.2265\n","2021-09-29 07:11:26,552 - mmdet - INFO - Epoch [8][20/25]\tlr: 2.500e-03, eta: 0:00:29, time: 0.233, data_time: 0.009, memory: 2389, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0091, loss_cls: 0.0827, acc: 96.8457, loss_bbox: 0.1648, loss: 0.2587\n","2021-09-29 07:11:32,195 - mmdet - INFO - Epoch [9][10/25]\tlr: 2.500e-04, eta: 0:00:25, time: 0.443, data_time: 0.218, memory: 2389, loss_rpn_cls: 0.0011, loss_rpn_bbox: 0.0088, loss_cls: 0.0696, acc: 97.4707, loss_bbox: 0.1333, loss: 0.2128\n","2021-09-29 07:11:34,536 - mmdet - INFO - Epoch [9][20/25]\tlr: 2.500e-04, eta: 0:00:22, time: 0.234, data_time: 0.009, memory: 2389, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0076, loss_cls: 0.0670, acc: 97.2168, loss_bbox: 0.1285, loss: 0.2053\n","2021-09-29 07:11:40,200 - mmdet - INFO - Epoch [10][10/25]\tlr: 2.500e-04, eta: 0:00:18, time: 0.444, data_time: 0.217, memory: 2389, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0089, loss_cls: 0.0744, acc: 97.0898, loss_bbox: 0.1422, loss: 0.2295\n","2021-09-29 07:11:42,537 - mmdet - INFO - Epoch [10][20/25]\tlr: 2.500e-04, eta: 0:00:15, time: 0.234, data_time: 0.010, memory: 2389, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0065, loss_cls: 0.0646, acc: 97.4219, loss_bbox: 0.1253, loss: 0.1981\n","2021-09-29 07:11:48,168 - mmdet - INFO - Epoch [11][10/25]\tlr: 2.500e-04, eta: 0:00:11, time: 0.442, data_time: 0.217, memory: 2389, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0079, loss_cls: 0.0757, acc: 97.2656, loss_bbox: 0.1308, loss: 0.2166\n","2021-09-29 07:11:50,520 - mmdet - INFO - Epoch [11][20/25]\tlr: 2.500e-04, eta: 0:00:08, time: 0.235, data_time: 0.010, memory: 2389, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0089, loss_cls: 0.0669, acc: 97.6562, loss_bbox: 0.1334, loss: 0.2120\n","2021-09-29 07:11:56,181 - mmdet - INFO - Epoch [12][10/25]\tlr: 2.500e-05, eta: 0:00:04, time: 0.444, data_time: 0.218, memory: 2389, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0064, loss_cls: 0.0634, acc: 97.4609, loss_bbox: 0.1193, loss: 0.1915\n","2021-09-29 07:11:58,512 - mmdet - INFO - Epoch [12][20/25]\tlr: 2.500e-05, eta: 0:00:01, time: 0.233, data_time: 0.009, memory: 2389, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0063, loss_cls: 0.0611, acc: 97.5195, loss_bbox: 0.0994, loss: 0.1697\n","2021-09-29 07:11:59,659 - mmdet - INFO - Saving checkpoint at 12 epochs\n"]},{"output_type":"stream","name":"stdout","text":["[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 25/25, 15.9 task/s, elapsed: 2s, ETA:     0s\n","---------------iou_thr: 0.5---------------\n"]},{"output_type":"stream","name":"stderr","text":["2021-09-29 07:12:02,012 - mmdet - INFO - \n","+------------+-----+------+--------+-------+\n","| class      | gts | dets | recall | ap    |\n","+------------+-----+------+--------+-------+\n","| Car        | 62  | 147  | 0.903  | 0.819 |\n","| Pedestrian | 13  | 54   | 0.923  | 0.796 |\n","| Cyclist    | 7   | 61   | 0.571  | 0.095 |\n","+------------+-----+------+--------+-------+\n","| mAP        |     |      |        | 0.570 |\n","+------------+-----+------+--------+-------+\n","2021-09-29 07:12:02,015 - mmdet - INFO - Epoch(val) [12][25]\tAP50: 0.5700, mAP: 0.5700\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OP3iPM5jYElT","executionInfo":{"status":"ok","timestamp":1632902113030,"user_tz":-540,"elapsed":852974,"user":{"displayName":"장경희","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05148120440289478711"}},"outputId":"82747871-7dc2-49dd-ce19-74d06f567272"},"source":["import cv2\n","import mmcv\n","\n","model.cfg = cfg\n","\n","video_reader = mmcv.VideoReader(\"/content/data/songdo_driving_Trim2.mp4\")\n","video_writer = None\n","\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","video_writer = cv2.VideoWriter(\"/content/data/songdo_driving_Trim2_out.mp4\", fourcc, \n","                               video_reader.fps, (video_reader.width, video_reader.height))\n","\n","for frame in mmcv.track_iter_progress(video_reader):\n","  result = inference_detector(model, frame)\n","  frame = model.show_result(frame, result, score_thr=0.4)\n","  video_writer.write(frame)\n","\n","if video_writer:\n","  video_writer.release()"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["[                                                  ] 0/2939, elapsed: 0s, ETA:"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/mmdet-2.17.0-py3.7.egg/mmdet/datasets/utils.py:69: UserWarning: \"ImageToTensor\" pipeline is replaced by \"DefaultFormatBundle\" for batch inference. It is recommended to manually replace it in the test data pipeline in your config file.\n","  'data pipeline in your config file.', UserWarning)\n","/usr/local/lib/python3.7/dist-packages/mmdet-2.17.0-py3.7.egg/mmdet/core/anchor/anchor_generator.py:324: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n","  warnings.warn('``grid_anchors`` would be deprecated soon. '\n","/usr/local/lib/python3.7/dist-packages/mmdet-2.17.0-py3.7.egg/mmdet/core/anchor/anchor_generator.py:361: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n","  '``single_level_grid_anchors`` would be deprecated soon. '\n"]},{"output_type":"stream","name":"stdout","text":["[>>>>>>>>>>>>>>>>>>>>>>>>>>>] 2939/2939, 3.4 task/s, elapsed: 853s, ETA:     0s\n"]}]},{"cell_type":"code","metadata":{"id":"eegf1jSDfwyd"},"source":[""],"execution_count":null,"outputs":[]}]}